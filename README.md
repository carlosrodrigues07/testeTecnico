# üìã Relat√≥rio T√©cnico Detalhado ‚Äì Detec√ß√£o de Falhas Mec√¢nicas (MAFAULDA)

**Autor:** Carlos Henrique Rodrigues P.

---

## üìå Introdu√ß√£o

Este relat√≥rio foi elaborado para **explicar de forma clara, detalhada e justificada** todas as decis√µes t√©cnicas implementadas no notebook do *Desafio T√©cnico ‚Äì Detec√ß√£o de Falhas Mec√¢nicas*.

O objetivo do trabalho √© classificar automaticamente sinais de vibra√ß√£o do dataset **MAFAULDA**, distinguindo entre:

* **Classe 0 ‚Äì Opera√ß√£o Normal**
* **Classe 1 ‚Äì Desbalanceamento Mec√¢nico**

Todo o pipeline foi desenvolvido com foco em **clareza, reprodutibilidade e alinhamento com pr√°ticas industriais**.

---

## üéØ 1. Contexto do Problema e Objetivo

### 1.1 Dataset MAFAULDA

O dataset MAFAULDA √© composto por sinais de vibra√ß√£o obtidos a partir de um **simulador de falhas mec√¢nicas (MFS ‚Äì Machinery Fault Simulator)**.

**Caracter√≠sticas principais:**

* Sinais experimentais reais (n√£o sint√©ticos)
* Ambiente controlado de laborat√≥rio
* Arquivos CSV independentes
* Frequ√™ncia de amostragem: **1000 Hz**
* M√∫ltiplos canais por arquivo (foi utilizado **apenas um canal**, propositalmente)

Essa escolha torna o problema mais realista, pois em aplica√ß√µes industriais muitas vezes **nem todos os sensores est√£o dispon√≠veis**.

### 1.2 Objetivo do Projeto

Desenvolver um classificador bin√°rio capaz de identificar automaticamente o estado mec√¢nico do sistema a partir de sinais de vibra√ß√£o, seguindo tr√™s princ√≠pios:

1. Pipeline simples e interpret√°vel
2. Decis√µes t√©cnicas justificadas fisicamente
3. Avalia√ß√£o justa e reproduz√≠vel

---

## üß© 2. Estrat√©gia Global da Solu√ß√£o

O pipeline segue a abordagem cl√°ssica de *Machine Learning* aplicada a sinais temporais:

```
Carregamento ‚Üí Pr√©-processamento ‚Üí Janelamento ‚Üí Extra√ß√£o de Features ‚Üí Modelagem ‚Üí Avalia√ß√£o
```

**Filosofia adotada:**

* Come√ßar simples e evoluir com base nos dados
* Priorizar m√©todos explic√°veis (importante em contexto industrial)
* Evitar solu√ß√µes excessivamente complexas para um dataset limitado

---

## üîç 3. Carregamento e An√°lise Inicial dos Dados

Os arquivos CSV s√£o carregados separadamente para cada classe (Normal e Desbalanceamento). Cada arquivo representa uma execu√ß√£o independente do sistema.

Uma an√°lise inicial revelou:

* Diferen√ßa clara de **amplitude** entre classes
* Presen√ßa de **offset DC** (valor m√©dio diferente de zero)
* Ru√≠do de baixa frequ√™ncia n√£o relacionado √† falha

Essas observa√ß√µes guiaram diretamente as escolhas de pr√©-processamento.

---

## üîß 4. Pr√©-processamento dos Sinais

O pr√©-processamento foi tratado como uma etapa **cr√≠tica**, pois sinais de vibra√ß√£o reais s√£o naturalmente ruidosos.

### 4.1 Remo√ß√£o da Componente DC

```python
from scipy.signal import detrend

def remover_dc(sinal):
    return detrend(sinal, type='constant')
```

**Motiva√ß√£o:**

* Sensores reais frequentemente apresentam deslocamento do zero
* O offset DC n√£o carrega informa√ß√£o sobre falhas
* Pode distorcer m√©tricas como RMS e PSD

A fun√ß√£o `detrend` √© numericamente est√°vel e amplamente utilizada em an√°lise de vibra√ß√£o.

---

### 4.2 Filtragem Passa-Banda (5‚Äì200 Hz)

```python
from scipy.signal import butter, filtfilt

def filtro_butter(sinal, fs, low=5, high=200, ordem=4):
    nyq = fs / 2
    b, a = butter(ordem, [low/nyq, high/nyq], btype='band')
    return filtfilt(b, a, sinal)
```

**Justificativa t√©cnica:**

* Frequ√™ncias abaixo de 5 Hz est√£o associadas a movimentos estruturais e instala√ß√£o
* Frequ√™ncias acima de 200 Hz apresentaram apenas ru√≠do
* O desbalanceamento mec√¢nico se manifesta principalmente em baixas e m√©dias frequ√™ncias

O filtro Butterworth foi escolhido por possuir resposta plana na banda passante.

---

### 4.3 Normaliza√ß√£o ‚Äì RobustScaler

```python
from sklearn.preprocessing import RobustScaler
```

**Por que RobustScaler?**

* Utiliza mediana e intervalo interquartil
* Muito menos sens√≠vel a outliers
* Ideal para sinais experimentais com picos ocasionais

Essa escolha √© particularmente importante porque falhas mec√¢nicas podem gerar **valores extremos reais**, que n√£o devem ser removidos.

---

## ü™ü 5. Janelamento dos Sinais

Como cada arquivo possui milhares de amostras, foi aplicada segmenta√ß√£o em janelas deslizantes:

```python
def dividir_janelas(sinal, tamanho=2048, overlap=0.5):
    passo = int(tamanho * (1 - overlap))
    return [sinal[i:i+tamanho] for i in range(0, len(sinal)-tamanho, passo)]
```

**Par√¢metros escolhidos:**

* Janela: 2048 amostras (~2 segundos)
* Overlap: 50%

**Benef√≠cios:**

* Aumento significativo do n√∫mero de amostras
* Preserva√ß√£o da continuidade temporal
* Melhor generaliza√ß√£o dos modelos

---

## üßÆ 6. Extra√ß√£o de Features

Foram escolhidas features **simples, interpret√°veis e fisicamente significativas**.

### 6.1 Features no Dom√≠nio do Tempo

* **RMS:** energia do sinal
* **Curtose:** sensibilidade a impactos
* **Skewness:** assimetria da vibra√ß√£o

Essas m√©tricas s√£o amplamente utilizadas em manuten√ß√£o preditiva.

### 6.2 Features no Dom√≠nio da Frequ√™ncia

A densidade espectral de pot√™ncia foi calculada usando o m√©todo de Welch:

```python
from scipy.signal import welch
```

Features extra√≠das:

* Frequ√™ncia dominante
* Pot√™ncia total

Apesar de calculadas, essas features mostraram menor poder discriminativo.

---

## ‚öñÔ∏è 7. Tratamento do Desbalanceamento das Classes

Ap√≥s o janelamento, ainda havia desbalanceamento entre as classes.

Foi utilizado **SMOTE apenas no conjunto de treino**:

```python
from imblearn.over_sampling import SMOTE
```

Essa abordagem evita *data leakage* e melhora a capacidade de generaliza√ß√£o.

---

## ü§ñ 8. Modelagem de Machine Learning

### 8.1 Random Forest

* Robusto a ru√≠do
* Interpret√°vel
* Excelente baseline industrial

### 8.2 XGBoost

* Gradient boosting
* Regulariza√ß√£o nativa
* Alta performance em dados tabulares

Ambos foram treinados sob as mesmas condi√ß√µes para garantir compara√ß√£o justa.

---

## üìä 9. Avalia√ß√£o dos Modelos

### M√©tricas utilizadas:

* **Acur√°cia** (vis√£o geral)
* **F1-score** (principal m√©trica)
* **ROC-AUC** (capacidade discriminativa)

A valida√ß√£o cruzada estratificada foi utilizada durante o desenvolvimento.

---

## üìà 10. Resultados Obtidos

* Random Forest apresentou melhor equil√≠brio entre precis√£o e recall
* F1-score em torno de **0.74**, considerado adequado dada a dificuldade do problema
* ROC-AUC pr√≥ximo de **0.55**, indicando separa√ß√£o limitada entre classes

Isso refor√ßa que o problema √© **intrinsecamente desafiador** com features simples.

---

## üìù 11. Conclus√µes 

Este projeto demonstra:

* Capacidade de estruturar um pipeline completo de ML
* Tomada de decis√£o baseada em dados e dom√≠nio f√≠sico
* Preocupa√ß√£o com boas pr√°ticas (evitar data leakage, valida√ß√£o justa)
* Clareza na comunica√ß√£o t√©cnica

A solu√ß√£o n√£o busca apenas maximizar m√©tricas, mas **resolver o problema de forma correta, explic√°vel e reproduz√≠vel**, como exigido em ambientes industriais reais.

---

## üöÄ 12. Pr√≥ximos Passos Sugeridos

* Inclus√£o de m√∫ltiplos canais
* Features tempo-frequ√™ncia (wavelets)
* Modelos deep learning (CNN 1D)
* Explainable AI (SHAP)
* Pipeline em tempo real


